# Assignment 4: Gaussian Mixture Models for Synthetic Sampling

---

## ‚úçÔ∏è Author
Name : Gudla Chakradhara Venkata Sairam  
Roll No : DA25M012  
Department : Data Science and Artificial Intelligence, M.Tech  

---

## üìå Overview
This project explores the use of **Gaussian Mixture Models (GMMs)** for synthetic data generation in the context of imbalanced datasets. The goal is to compare GMM-based oversampling with baseline models and a combined approach using **ClusterCentroids undersampling (CBU) + GMM oversampling**. The case study is based on the **Credit Card Fraud Detection dataset**, which suffers from extreme class imbalance.

---

## üìÇ Files
- `Assignment-4_GMMs.ipynb` ‚Üí Implementation notebook.  
- `README.md` ‚Üí Project description (this file).

---

## ‚öôÔ∏è Methodology
1. **Dataset**
   - Majority class: ~227,000 samples  
   - Minority class: ~400 samples  
   - The dataset was already scaled, so no further preprocessing was needed.

2. **ClusterCentroids Undersampling (CBU)**
   - Applied to reduce the majority class to a more reasonable size.
   - Number of majority samples was controlled to avoid overfitting and allow GMM to learn minority structure.

3. **Gaussian Mixture Model (GMM)**
   - Fitted only on the **minority class data**.
   - Optimal number of mixture components **k** chosen using **Bayesian Information Criterion (BIC)**, which penalizes complexity more strictly than AIC.
   - Synthetic samples generated by sampling from the fitted GMM.

4. **Experimental Models**
   - **Baseline:** Classifier trained on imbalanced data without resampling.  
   - **GMM Oversampling:** Minority class balanced by GMM-generated synthetic samples.  
   - **CBU + GMM:** Combination of ClusterCentroids undersampling (majority) and GMM oversampling (minority).  

---

## üìä Results
Performance was evaluated on the **minority class** using **Precision, Recall, and F1-score**:

| Model     | Precision | Recall  | F1-score |
|-----------|-----------|---------|----------|
| Baseline  | 0.829     | 0.643   | 0.724    |
| GMM       | 0.080     | 0.908   | 0.146    |
| CBU + GMM | 0.086     | 0.898   | 0.157    |

---

## üîé Analysis
- The **baseline** model showed high precision but relatively poor recall, meaning it missed a significant portion of fraud cases.  
- **GMM oversampling** drastically improved recall (‚âà0.91), ensuring most fraud cases were detected, though precision dropped sharply.  
- **CBU + GMM** achieved a similar recall but slightly better precision, leading to a higher F1-score than plain GMM.  
- Since fraud detection prioritizes **recall** (catching all frauds is more important than false alarms), GMM-based methods are superior to the baseline.  

---

## ‚úÖ Final Recommendation
- **Use GMM-based oversampling (with or without CBU) when recall is the primary objective.**  
- **CBU + GMM** is recommended when a small improvement in F1-score and precision is desired without sacrificing recall.  
